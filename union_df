#!/usr/bin/env python
# coding: utf-8

# In[1]:


# Объединение датаФреймов
# работа сразу с несколькими файлами однотипных типами данных
# будем разбивать наш файл на два новых
import pandas as pd


# In[2]:


# dataFrame
# наша библиотека с названием pd
df = pd.read_csv('file2.csv')
# получим количество строк и столбцов
print(df.shape)


# In[3]:


# или можно обратиться к нулевому элементу и получить количество строк
print(df.shape[0])


# In[5]:


# переменная для именования файлов
num = 1
#цикл *от 0, поэтому, до df.shape[0], шаг 5к (чтоб разбмить файл на 5 файлов по 5к строк)
for i in range(0, df.shape[0], 5000):
    temp = df.loc[i: i + 5000 - 1] # -1 чтобы не дублировались строки
    # прочитаем только часть строк - df.loc[] - срез строк
    # из временной переменной создадим файлы
    # в папку, которую создали parts
    temp.to_csv(f'parts/part_{num}.csv', index=False)
    # переменная num вставлена для именования, которую будем инкремитировать в каждой итерации
    # index на не нужны, поэтоиму их не будем записывать
    num = num + 1


# In[ ]:


# готово


# In[ ]:





# In[ ]:





# In[10]:


# теперь наоборот объедими датафреймы и файл в один df_all file_all.csv
import os # для работы с файловой системой
df_all = pd.DataFrame() # пустой датафрейм
# создадим стандартный цикл прохода по директории и считывания файлов
for f in os.listdir('parts/'):
    print(f) # выведу на экран список файлов лежайщий в директории
    # далее нам надо будет прочесть датафреймы
    temp = pd.read_csv('parts/' + f) # читаем диреторию + файл 
    # объединим все датафреймы в один общий через concat
    df_all = pd.concat([df_all, temp])


# In[11]:


print(df_all)


# In[12]:


# готово, в датафрейме собраны данные из 5 файлов всей директории
# также тут ви дно, что индыксы поаторяются, для удобства можно переиндексировать
# параметры nplace переиндексировать и удалить drop старые индексы
df_all.reset_index(inplace=True, drop=True)
print(df_all)


# In[ ]:




